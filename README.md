# RL: Race and Learn â€“ Summer of Codes 2025 (SOC, WNCC IIT Bombay)

This project explores Reinforcement Learning fundamentals through weekly tasks, assignments, and implementations in Python.

---

## ðŸ“š Weekly Progress

### Week 1
I built a Snake game using the Pygame library. This helped me get comfortable with event-driven programming in Python and understand concepts like collision detection, game loops, and real-time rendering.

### Week 2
I implemented a fully connected feedforward neural network using PyTorch and trained it on the MNIST dataset. I learned about layers, activation functions, forward and backward passes, and optimization using stochastic gradient descent. I also gained hands-on experience with loss functions, model evaluation, and visualization of results.

### Week 3
I focused on learning the theoretical foundations of reinforcement learning. This included understanding Markov Decision Processes (MDPs), value functions, policies, and Bellman equations. I also explored the differences between model-based and model-free approaches and the concept of policy iteration vs. value iteration.

### Week 4
I delved deeper into reinforcement learning by studying Q-learning and Deep Q Networks (DQN). I learned how to implement Q-learning in gridworld environments and understood the importance of techniques like experience replay and target networks. I also explored the difference between traditional tabular methods and function approximation.

---

## âœ¨ Learnings & Highlights

* Writing games is a fun way to practise real-time loops & state machines.
* Training a neural network from scratch helped solidify my understanding of optimization and overfitting.
* Reinforcement learning emphasizes long-term reward optimization and requires careful balance between exploration and exploitation.
* Techniques like experience replay and target networks improve the stability of deep reinforcement learning models.
